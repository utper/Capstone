{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/utper/Capstone/blob/master/2-2-7-ExploringCategorical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL2nKxjS4S_r"
      },
      "source": [
        "# Start with a simple neural network for MNIST\n",
        "Note that there are 2 layers, one with 20 neurons, and one with 10.\n",
        "\n",
        "The 10-neuron layer is our final layer because we have 10 classes we want to classify.\n",
        "\n",
        "Train this, and you should see it get about 98% accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eylR8zbmn13x"
      },
      "outputs": [],
      "source": [
        "# Este código entrena una red neuronal para reconocer números escritos a mano.\n",
        "# Load libraries\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zwwRJsoBn130"
      },
      "outputs": [],
      "source": [
        "# This script requires TensorFlow 2 and Python 3.\n",
        "if sys.version_info.major < 3:\n",
        "    raise Exception((f\"The script is developed and tested for Python 3. \"\n",
        "                     f\"Current version: {sys.version_info.major}\"))\n",
        "\n",
        "if tf.__version__.split('.')[0] != '2':\n",
        "    raise Exception((f\"The script is developed and tested for tensorflow 2. \"\n",
        "                     f\"Current version: {tf.__version__}\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Funciones de activación:**\n",
        "\n",
        "1.- ReLU (Rectified Linear Unit)\n",
        "* Se usa en la capa oculta de la red neuronal.\n",
        "* Su fórmula es:\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "* Convierte valores negativos en cero y deja los positivos iguales.\n",
        "* Es popular porque introduce no linealidad y evita problemas como el desvanecimiento del gradiente.\n",
        "* Ayuda a que el modelo aprenda patrones complejos y acelera el entrenamiento.\n",
        "\n",
        "2.- Softmax\n",
        "* Se usa en la capa de salida cuando el problema es clasificación.\n",
        "* Convierte las salidas de la red en probabilidades para cada clase.\n",
        "* Su fórmula es:\n",
        "![image.png](data:image/png;base64,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)\n",
        "* Cada salida estará entre 0 y 1 y la suma total de todas las clases será 1.\n",
        "* Permite que el modelo haga una predicción indicando la clase más probable.\n",
        "\n",
        "En tu modelo, relu ayuda a extraer características importantes de las imágenes y softmax convierte la predicción en probabilidades comprensibles."
      ],
      "metadata": {
        "id": "VdIy1GLW8XEd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrQ-DeQtybXZ",
        "outputId": "0973ca1a-14a0-4818-d9f7-49b3c498879f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8075 - loss: 0.6636 - val_accuracy: 0.9225 - val_loss: 0.2628\n",
            "Epoch 2/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 0.2526 - val_accuracy: 0.9363 - val_loss: 0.2199\n",
            "Epoch 3/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9384 - loss: 0.2136 - val_accuracy: 0.9427 - val_loss: 0.1962\n",
            "Epoch 4/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9487 - loss: 0.1755 - val_accuracy: 0.9495 - val_loss: 0.1775\n",
            "Epoch 5/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9528 - loss: 0.1617 - val_accuracy: 0.9535 - val_loss: 0.1616\n",
            "Epoch 6/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9565 - loss: 0.1503 - val_accuracy: 0.9535 - val_loss: 0.1631\n",
            "Epoch 7/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.1365 - val_accuracy: 0.9560 - val_loss: 0.1519\n",
            "Epoch 8/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.1264 - val_accuracy: 0.9543 - val_loss: 0.1535\n",
            "Epoch 9/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.1165 - val_accuracy: 0.9563 - val_loss: 0.1456\n",
            "Epoch 10/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9657 - loss: 0.1174 - val_accuracy: 0.9567 - val_loss: 0.1456\n",
            "Epoch 11/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9677 - loss: 0.1086 - val_accuracy: 0.9577 - val_loss: 0.1423\n",
            "Epoch 12/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9682 - loss: 0.1036 - val_accuracy: 0.9552 - val_loss: 0.1454\n",
            "Epoch 13/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9712 - loss: 0.0953 - val_accuracy: 0.9605 - val_loss: 0.1363\n",
            "Epoch 14/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9722 - loss: 0.0956 - val_accuracy: 0.9583 - val_loss: 0.1438\n",
            "Epoch 15/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9737 - loss: 0.0882 - val_accuracy: 0.9603 - val_loss: 0.1381\n",
            "Epoch 16/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9742 - loss: 0.0889 - val_accuracy: 0.9611 - val_loss: 0.1329\n",
            "Epoch 17/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9747 - loss: 0.0829 - val_accuracy: 0.9616 - val_loss: 0.1340\n",
            "Epoch 18/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9742 - loss: 0.0837 - val_accuracy: 0.9625 - val_loss: 0.1321\n",
            "Epoch 19/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9754 - loss: 0.0810 - val_accuracy: 0.9638 - val_loss: 0.1305\n",
            "Epoch 20/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9775 - loss: 0.0761 - val_accuracy: 0.9638 - val_loss: 0.1311\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e86541472d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Carga del conjunto de datos MNIST:\n",
        "# Cuando decimos que \"cargamos los datos de MNIST\", nos referimos a obtener el conjunto de datos de imágenes y etiquetas que forman\n",
        "# parte de la base de datos MNIST.\n",
        "# Esta base de datos contiene 70,000 imágenes de dígitos escritos a mano (del 0 al 9), con 60,000 imágenes para entrenamiento y 10,000\n",
        "# para validación.\n",
        "# * training_images y training_labels: se usan para entrenar el modelo.\n",
        "# * val_images y val_labels: se usan para evaluar qué tan bien funciona el modelo con datos nuevos.\n",
        "# Cada imagen es una matriz de 28x28 píxeles en escala de grises, y las etiquetas indican qué número representa cada imagen.\n",
        "data = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (val_images, val_labels) = data.load_data()\n",
        "\n",
        "# Normalización de imágenes:\n",
        "# Los valores de los píxeles en las imágenes de MNIST van de 0 a 255\n",
        "# Se escalan los valores de píxeles a un rango de 0 a 1 dividiéndolos por 255, lo que ayuda a la convergencia del entrenamiento.\n",
        "training_images  = training_images / 255.0\n",
        "val_images = val_images / 255.0\n",
        "\n",
        "# Definición del modelo:\n",
        "# Se crea una red neuronal con tres capas:\n",
        "# * Flatten: Convierte la imagen 28x28 en un vector de 784 elementos.\n",
        "# * Dense(20, activation=tf.nn.relu): Capa oculta con 20 neuronas y activación ReLU.\n",
        "# * Dense(10, activation=tf.nn.softmax): Capa de salida con 10 neuronas (una por cada dígito) y activación softmax para clasificación.\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "                                    tf.keras.layers.Dense(20, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "# Compilación del modelo:\n",
        "# Se usa el optimizador adam y la función de pérdida sparse_categorical_crossentropy, adecuada para clasificación con etiquetas enteras.\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Entrenamiento del modelo:\n",
        "# Se entrena la red durante 20 épocas con las imágenes y etiquetas de entrenamiento, validando con imágenes y etiquetas de validación.\n",
        "model.fit(training_images, training_labels, epochs=20, validation_data=(val_images, val_labels))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "k7Yrcpfj7-NO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN92xbwK4i_S"
      },
      "source": [
        "## Examine the test data\n",
        "\n",
        "Using model.evaluate, you can get metrics for a test set. In this case we only have a training set and a validation set, so we can try it out with the validation set. The accuracy will be slightly lower, at maybe 96%.  This is because the model hasn't previously seen this data and may not be fully generalized for all data. Still it's a pretty good score.\n",
        "\n",
        "You can also predict images, and compare against their actual label. The [0] image in the set is a number 7, and here you can see that neuron 7 has a 9.9e-1 (99%+) probability, so it got it right!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rzit5Te-4lT6",
        "outputId": "b5023f22-0c4d-443d-f431-9e7e95d92339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9585 - loss: 0.1487\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "[4.9218731e-09 2.6859456e-10 2.5543623e-05 8.9697947e-04 1.8457190e-10\n",
            " 7.1628023e-08 6.5522398e-16 9.9907434e-01 2.4159974e-06 6.4694331e-07]\n",
            "7\n"
          ]
        }
      ],
      "source": [
        "# Evaluación del modelo:\n",
        "# Se evalúa la precisión del modelo con datos de validación.\n",
        "model.evaluate(val_images, val_labels)\n",
        "\n",
        "# Predicciones:\n",
        "# Se obtienen predicciones para imágenes de validación. La primera predicción (classifications[0]) es un arreglo con 10 probabilidades\n",
        "# (una por cada dígito). El print(val_labels[0]) muestra la etiqueta real de la primera imagen.\n",
        "classifications = model.predict(val_images)\n",
        "print(classifications[0])\n",
        "print(val_labels[0])\n",
        "\n",
        "# Observando el resultado, si observamos el vector de probabilidades, la posición 7 tiene el mayor valor = 9.9907434e-01.\n",
        "# Este número es casi 1, lo que indica que el modelo está muy seguro de que la imagen representa un 7. Las demás probabilidades son muy\n",
        "# pequeñas (cerca de cero), lo que significa que el modelo descarta casi por completo las otras opciones.\n",
        "# Esto demuestra que el modelo ha aprendido correctamente a reconocer el dígito en la imagen.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LkJGAiI5Cr3"
      },
      "source": [
        "## Modify to inspect learned values\n",
        "\n",
        "This code is identical, except that the layers are named prior to adding to the sequential. This allows us to inspect their learned parameters later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyyJ3RMYpFXR",
        "outputId": "b5de0928-343e-45b9-9345-04ce60477d81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8080 - loss: 0.6607\n",
            "Epoch 2/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9352 - loss: 0.2244\n",
            "Epoch 3/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9434 - loss: 0.1888\n",
            "Epoch 4/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9505 - loss: 0.1662\n",
            "Epoch 5/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9558 - loss: 0.1542\n",
            "Epoch 6/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9598 - loss: 0.1382\n",
            "Epoch 7/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9633 - loss: 0.1284\n",
            "Epoch 8/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9642 - loss: 0.1230\n",
            "Epoch 9/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9670 - loss: 0.1119\n",
            "Epoch 10/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9673 - loss: 0.1091\n",
            "Epoch 11/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9698 - loss: 0.1025\n",
            "Epoch 12/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9705 - loss: 0.0982\n",
            "Epoch 13/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9724 - loss: 0.0956\n",
            "Epoch 14/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.0928\n",
            "Epoch 15/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9731 - loss: 0.0874\n",
            "Epoch 16/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9741 - loss: 0.0827\n",
            "Epoch 17/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9748 - loss: 0.0833\n",
            "Epoch 18/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9772 - loss: 0.0770\n",
            "Epoch 19/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9750 - loss: 0.0784\n",
            "Epoch 20/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.0748\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9507 - loss: 0.1752\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "[1.2601220e-06 7.1813266e-15 2.0994933e-06 4.6328173e-04 4.1163595e-08\n",
            " 2.1170145e-07 3.0805314e-22 9.9952602e-01 3.7403694e-07 6.8481954e-06]\n",
            "7\n"
          ]
        }
      ],
      "source": [
        "data = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels), (val_images, val_labels) = data.load_data()\n",
        "\n",
        "training_images  = training_images / 255.0\n",
        "val_images = val_images / 255.0\n",
        "layer_1 = tf.keras.layers.Dense(20, activation=tf.nn.relu)\n",
        "layer_2 = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "                                    layer_1,\n",
        "                                    layer_2])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=20)\n",
        "\n",
        "model.evaluate(val_images, val_labels)\n",
        "\n",
        "classifications = model.predict(val_images)\n",
        "print(classifications[0])\n",
        "print(val_labels[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código implementa una Red Neuronal Profunda (DNN, Deep Neural Network). Veamos por qué:\n",
        "\n",
        "**1.- Estructura de capas**\n",
        "* Usa Sequential(), lo que define una arquitectura de red neuronal con múltiples capas.\n",
        "* Tiene una capa oculta Dense(20, activation=tf.nn.relu), que es característica de una DNN.\n",
        "* Usa relu en la capa oculta, lo cual es común en redes neuronales profundas porque mejora el aprendizaje.\n",
        "\n",
        "**2.- Entrenamiento supervisado**\n",
        "Se dice que este entrenamiento es supervisado porque el modelo aprende a partir de datos etiquetados, es decir, imágenes con sus correspondientes etiquetas correctas.\n",
        "* Se entrena con imágenes y etiquetas (training_images, training_labels).\n",
        "* Usa adam como optimizador, lo que ayuda a ajustar los pesos de la red de manera eficiente.\n",
        "* Ajusta los parámetros mediante retropropagación.\n",
        "\n",
        "**3.- Profundidad de la red**\n",
        "* Aunque tiene pocas capas comparado con modelos más avanzados, sigue siendo una red neuronal profunda porque tiene varias capas densas.\n",
        "* Puede capturar patrones más complejos que un modelo de regresión o una simple Perceptrón Multicapa (MLP).\n",
        "\n",
        "Este modelo es una DNN básica, aunque hay redes más profundas con muchas más capas ocultas. Si quisieras una CNN (Red Neuronal Convolucional), podríamos agregar capas convolucionales para mejorar la detección de características en imágenes."
      ],
      "metadata": {
        "id": "juAjkusT_HFd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pNYFF935PlE"
      },
      "source": [
        "# Inspect weights\n",
        "\n",
        "If you print layer_1.get_weights(), you'll see a lot of data. Let's unpack it. First, there are 2 arrays in the result, so let's look at the first one. In particular let's look at its size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QACivjNKxFWW",
        "outputId": "0f7cab86-d20d-43df-8653-17c95affc441"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15680\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 1️⃣ layer_1.get_weights()\n",
        "# * layer_1 es una capa de la red neuronal.\n",
        "# * get_weights() devuelve una lista con los parámetros de la capa:\n",
        "#      * get_weights()[0] → Matriz de pesos (conexiones entre neuronas).\n",
        "#      * get_weights()[1] → Vector de sesgos (bias).\n",
        "# 2️⃣ get_weights()[0].size\n",
        "# * get_weights()[0] es la matriz de pesos de la capa.\n",
        "# * .size devuelve el número total de elementos en la matriz de pesos.\n",
        "#       * Si la capa tiene, por ejemplo, 28 * 28 * 20 conexiones (entrada de 28x28 y 20 neuronas), entonces .size devolvería 15680.\n",
        "print(layer_1.get_weights()[0].size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqpHrDyp5acs"
      },
      "source": [
        "The above code should print 15680. Why?\n",
        "\n",
        "Recall that there are 20 neurons in the first layer.\n",
        "\n",
        "Recall also that the images are 28x28, which is 784.\n",
        "\n",
        "If you multiply 784 x 20 you get 15680.\n",
        "\n",
        "So...this layer has 20 neurons, and each neuron learns a W parameter for each pixel. So instead of y=Mx+c, we have\n",
        "y=M1X1+M2X2+M3X3+....+M784X784+C in every neuron!\n",
        "\n",
        "Every pixel has a weight in every neuron. Those weights are multiplied by the pixel value, summed up, and given a bias.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdXrHDEw6ACm",
        "outputId": "0af9505f-3950-43c7-ef80-96e4c7b36b27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        }
      ],
      "source": [
        "print(layer_1.get_weights()[1].size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIOZ7rJy6Eg1"
      },
      "source": [
        "The above code will give you 20 -- the get_weights()[1] contains the biases for each of the 20 neurons in this layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyFKpzxN6T-N"
      },
      "source": [
        "## Inspecting layer 2\n",
        "\n",
        "Now let's look at layer 2. Printing the get_weights will give us 2 lists, the first a list of weights for the 10 neurons, and the second a list of biases for the 10 neurons\n",
        "\n",
        "Let's look first at the weights:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9P_PVwXyKXJ",
        "outputId": "ea9128b3-30e8-4773-a60f-310cb632fc50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n"
          ]
        }
      ],
      "source": [
        "print(layer_2.get_weights()[0].size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daah2gq56fdb"
      },
      "source": [
        "This should return 200. Again, consider why?\n",
        "\n",
        "There are 10 neurons in this layer, but there are 20 neurons in the previous layer. So, each neuron in this layer will learn a weight for the incoming value from the previous layer. So, for example, the if the first neuron in this layer is N21, and the neurons output from the previous layers are N11-N120, then this neuron will have 20 weights (W1-W20) and it will calculate its output to be:\n",
        "\n",
        "W1N11+W2N12+W3N13+...+W20N120+Bias\n",
        "\n",
        "So each of these weights will be learned as will the bias, for every neuron.\n",
        "\n",
        "Note that N11 refers to Layer 1 Neuron 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Reyw9wC65o8z",
        "outputId": "063835b9-4b09-4431-a41e-6479791677fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ],
      "source": [
        "print(layer_2.get_weights()[1].size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS89WZag7GlB"
      },
      "source": [
        "...and as expected there are 10 elements in this array, representing the 10 biases for the 10 neurons.\n",
        "\n",
        "Hopefully this helps you see how the element of a simple neuron containing y=mx+c can be expanded greatly into a deep neural network, and that DNN can learn the parameters that match the 784 pixels of an image to their output!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Exploring_Categorical.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}