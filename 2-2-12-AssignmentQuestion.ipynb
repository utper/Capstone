{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwHrGhZRgi8H"
      },
      "source": [
        "# Exploring DNN learning with TensorFlow\n",
        "\n",
        "In this assignment we'll dive a little deeper with a series of hands on exercises to better understand DNN learning with Tensorflow. Remember that if you are taking the class for a certificate we will be asking you questions about the assignment in the test!\n",
        "\n",
        "We start by setting up the problem for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TgcoaNv2gi8M"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wXgJVgE8gi8N"
      },
      "outputs": [],
      "source": [
        "# This script requires TensorFlow 2 and Python 3.\n",
        "if sys.version_info.major < 3:\n",
        "    raise Exception((f\"The script is developed and tested for Python 3. \"\n",
        "                     f\"Current version: {sys.version_info.major}\"))\n",
        "\n",
        "if tf.__version__.split('.')[0] != '2':\n",
        "    raise Exception((f\"The script is developed and tested for tensorflow 2. \"\n",
        "                     f\"Current version: {tf.__version__}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3KzJyjv3rnA",
        "outputId": "64a9de2f-ddaf-4951-d0e4-96844201f710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Load in fashion MNIST\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Define the base model\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las primeras 5 imÃ¡genes como arrays\n",
        "for i in range(5):\n",
        "    print(f\"Imagen {i}:\")\n",
        "    print(training_images[i])  # Esto mostrarÃ¡ la matriz de 28x28 de la imagen en formato de array\n",
        "    print(f\"Etiqueta: {training_labels[i]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXwttl4Phk3z",
        "outputId": "a7dc622c-2e2c-4bb8-efc4-f3e0bc10683b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagen 0:\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0\n",
            "    0   1   4   0   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62\n",
            "   54   0   0   0   1   3   4   0   0   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
            "  144 123  23   0   0   0   0  12  10   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178\n",
            "  107 156 161 109  64  23  77 130  72  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216\n",
            "  216 163 127 121 122 146 141  88 172  66]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229\n",
            "  223 223 215 213 164 127 123 196 229   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
            "  235 227 224 222 224 221 223 245 173   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198\n",
            "  180 212 210 211 213 223 220 243 202   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192\n",
            "  169 227 208 218 224 212 226 197 209  52]\n",
            " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203\n",
            "  198 221 215 213 222 220 245 119 167  56]\n",
            " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240\n",
            "  232 213 218 223 234 217 217 209  92   0]\n",
            " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219\n",
            "  222 221 216 223 229 215 218 255  77   0]\n",
            " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208\n",
            "  211 218 224 223 219 215 224 244 159   0]\n",
            " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230\n",
            "  224 234 176 188 250 248 233 238 215   0]\n",
            " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223\n",
            "  255 255 221 234 221 211 220 232 246   0]\n",
            " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
            "  188 154 191 210 204 209 222 228 225   0]\n",
            " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117\n",
            "  168 219 221 215 217 223 223 224 229  29]\n",
            " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245\n",
            "  239 223 218 212 209 222 220 221 230  67]\n",
            " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216\n",
            "  199 206 186 181 177 172 181 205 206 115]\n",
            " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191\n",
            "  195 191 198 192 176 156 167 177 210  92]\n",
            " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209\n",
            "  210 210 211 188 188 194 192 216 170   0]\n",
            " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179\n",
            "  182 182 181 176 166 168  99  58   0   0]\n",
            " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "Etiqueta: 9\n",
            "\n",
            "Imagen 1:\n",
            "[[  0   0   0   0   0   1   0   0   0   0  41 188 103  54  48  43  87 168\n",
            "  133  16   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   1   0   0   0  49 136 219 216 228 236 255 255 255 255 217\n",
            "  215 254 231 160  45   0   0   0   0   0]\n",
            " [  0   0   0   0   0  14 176 222 224 212 203 198 196 200 215 204 202 201\n",
            "  201 201 209 218 224 164   0   0   0   0]\n",
            " [  0   0   0   0   0 188 219 200 198 202 198 199 199 201 196 198 198 200\n",
            "  200 200 200 201 200 225  41   0   0   0]\n",
            " [  0   0   0   0  51 219 199 203 203 212 238 248 250 245 249 246 247 252\n",
            "  248 235 207 203 203 222 140   0   0   0]\n",
            " [  0   0   0   0 116 226 206 204 207 204 101  75  47  73  48  50  45  51\n",
            "   63 113 222 202 206 220 224   0   0   0]\n",
            " [  0   0   0   0 200 222 209 203 215 200   0  70  98   0 103  59  68  71\n",
            "   49   0 219 206 214 210 250  38   0   0]\n",
            " [  0   0   0   0 247 218 212 210 215 214   0 254 243 139 255 174 251 255\n",
            "  205   0 215 217 214 208 220  95   0   0]\n",
            " [  0   0   0  45 226 214 214 215 224 205   0  42  35  60  16  17  12  13\n",
            "   70   0 189 216 212 206 212 156   0   0]\n",
            " [  0   0   0 164 235 214 211 220 216 201  52  71  89  94  83  78  70  76\n",
            "   92  87 206 207 222 213 219 208   0   0]\n",
            " [  0   0   0 106 187 223 237 248 211 198 252 250 248 245 248 252 253 250\n",
            "  252 239 201 212 225 215 193 113   0   0]\n",
            " [  0   0   0   0   0  17  54 159 222 193 208 192 197 200 200 200 200 201\n",
            "  203 195 210 165   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  47 225 192 214 203 206 204 204 205 206 204\n",
            "  212 197 218 107   0   0   0   0   0   0]\n",
            " [  0   0   0   0   1   6   0  46 212 195 212 202 206 205 204 205 206 204\n",
            "  212 200 218  91   0   3   1   0   0   0]\n",
            " [  0   0   0   0   0   1   0  11 197 199 205 202 205 206 204 205 207 204\n",
            "  205 205 218  77   0   5   0   0   0   0]\n",
            " [  0   0   0   0   0   3   0   2 191 198 201 205 206 205 205 206 209 206\n",
            "  199 209 219  74   0   5   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   0 188 197 200 207 207 204 207 207 210 208\n",
            "  198 207 221  72   0   4   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   0 215 198 203 206 208 205 207 207 210 208\n",
            "  200 202 222  75   0   4   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 212 198 209 206 209 206 208 207 211 206\n",
            "  205 198 221  80   0   3   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 204 201 205 208 207 205 211 205 210 210\n",
            "  209 195 221  96   0   3   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 202 201 205 209 207 205 213 206 210 209\n",
            "  210 194 217 105   0   2   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 204 204 205 208 207 205 215 207 210 208\n",
            "  211 193 213 115   0   2   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 204 207 207 208 206 206 215 210 210 207\n",
            "  212 195 210 118   0   2   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 198 208 208 208 204 207 212 212 210 207\n",
            "  211 196 207 121   0   1   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 198 210 207 208 206 209 213 212 211 207\n",
            "  210 197 207 124   0   1   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 172 210 203 201 199 204 207 205 204 201\n",
            "  205 197 206 127   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 188 221 214 234 236 238 244 244 244 240\n",
            "  243 214 224 162   0   2   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 139 146 130 135 135 137 125 124 125 121\n",
            "  119 114 130  76   0   0   0   0   0   0]]\n",
            "Etiqueta: 0\n",
            "\n",
            "Imagen 2:\n",
            "[[  0   0   0   0   0   0   0   0   0  22 118  24   0   0   0   0   0  48\n",
            "   88   5   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  12 100 212 205 185 179 173 186 193 221\n",
            "  142  85   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  85  76 199 225 248 255 238 226 157\n",
            "   68  80   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  91  69  91 201 218 225 209 158  61\n",
            "   93  72   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  79  89  61  59  87 108  75  56  76\n",
            "   97  73   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  75  89  80  80  67  63  73  83  80\n",
            "   96  72   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  77  88  77  80  83  83  83  83  81\n",
            "   95  76   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  89  96  80  83  81  84  85  85  85\n",
            "   97  84   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  93  97  81  85  84  85  87  88  84\n",
            "   99  87   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  95  87  84  87  88  85  87  87  84\n",
            "   92  87   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  97  87  87  85  88  87  87  87  88\n",
            "   85 107   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  17 100  88  87  87  88  87  87  85  89\n",
            "   77 118   8   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  10  93  87  87  87  87  87  88  87  89\n",
            "   80 103   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   9  96  87  87  87  87  87  88  87  88\n",
            "   87 103   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  12  96  85  87  87  87  85  87  87  88\n",
            "   89 100   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  20  95  84  88  85  87  88  88  88  89\n",
            "   88  99   8   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  21  96  85  87  85  88  88  88  88  89\n",
            "   89  99  10   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  24  96  85  87  85  87  88  88  89  88\n",
            "   91 102  14   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  25  93  84  88  87  87  87  87  87  89\n",
            "   91 103  29   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  95  85  88  88  87  87  87  87  89\n",
            "   88 102  37   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  34  96  88  87  87  87  87  87  87  85\n",
            "   85  97  38   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  40  96  87  85  87  87  87  87  87  85\n",
            "   84  92  49   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  46  95  83  84  87  87  87  87  87  87\n",
            "   84  87  84   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  72  95  85  84  85  88  87  87  89  87\n",
            "   85  83  63   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  64 100  84  87  88  85  88  88  84  87\n",
            "   83  95  53   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  10 102 100  91  91  89  85  84  84  87\n",
            "  108 106  14   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   8  73  93 104 107 103 103 106 102\n",
            "   75  10   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   1   0   0   0  18  42  57  56  32   8\n",
            "    0   0   1   0   0   0   0   0   0   0]]\n",
            "Etiqueta: 0\n",
            "\n",
            "Imagen 3:\n",
            "[[  0   0   0   0   0   0   0   0  33  96 175 156  64  14  54 137 204 194\n",
            "  102   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  73 186 177 183 175 188 232 255 223 219 194 179\n",
            "  186 213 146   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  35 163 140 150 152 150 146 175 175 173 171 156 152\n",
            "  148 129 156 140   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 150 142 140 152 160 156 146 142 127 135 133 140 140\n",
            "  137 133 125 169  75   0   0   0   0   0]\n",
            " [  0   0   0   0   0  54 167 146 129 142 137 137 131 148 148 133 131 131\n",
            "  131 125 140 140   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 110 188 133 146 152 133 125 127 119 129 133 119\n",
            "  140 131 150  14   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 221 158 137 135 123 110 110 114 108 112 117\n",
            "  127 142  77   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   4   0  25 158 137 125 119 119 110 117 117 110 119\n",
            "  127 144   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 123 156 129 112 110 102 112 100 121 117\n",
            "  129 114   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 125 169 127 119 106 108 104  94 121 114\n",
            "  129  91   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   2   0  98 171 129 112 104 114 106 102 112 104\n",
            "  133  64   0   4   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   2   0  66 173 135 129  98 100 119 102 108  98\n",
            "  135  60   0   4   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   2   0  56 171 135 127 100 108 117  85 106 110\n",
            "  135  66   0   4   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  52 150 129 110 100  91 102  94  83 104\n",
            "  123  66   0   4   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   2   0  66 167 140 148 148 127 137 152 146 146\n",
            "  148  96   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  45 123  94 104  96 119 121 106  98 112\n",
            "   87 114   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 106  89  58  50  37  50  66  56  50  75\n",
            "   75 137  22   0   2   0   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0  29 148 114 106 125  89 100 133 117 131 131\n",
            "  131 125 112   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 100 106 114  91 137  62 102 131  89 135 112\n",
            "  131 108 135  37   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 146 100 108  98 144  62 106 131  87 133 104\n",
            "  160 117 121  68   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  33 121 108  96 100 140  71 106 127  85 140 104\n",
            "  150 140 114  89   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  62 119 112 102 110 137  75 106 144  81 144 108\n",
            "  117 154 117 104  18   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  66 121 102 112 117 131  73 104 156  77 137 135\n",
            "   83 179 129 121  35   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 127  81 125 133 119  79 100 169  83 129 175\n",
            "   60 163 135 146  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 106 129  62 140 144 108  85  83 158  85 129 175\n",
            "   48 146 133 135  64   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 117 119  79 140 152 102  89 110 137  96 150 196\n",
            "   83 144 135 133  77   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 154 121  87 140 154 112  94  52 142 100  83 152\n",
            "   85 160 133 100  12   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   4   0   2   0  35   4  33   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "Etiqueta: 3\n",
            "\n",
            "Imagen 4:\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  26\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 189 206 187  32   0   0   0  26 217 226\n",
            "  196  11   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 192 227 234 243 230 147 239 242 234 218\n",
            "  209   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 173 225 215 233 254   0 194 240 217 221\n",
            "  190   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 139 229 212 226 255   0 162 255 213 226\n",
            "  200   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  98 232 211 215 249  46 162 246 214 230\n",
            "  186   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  70 228 213 220 224 252 239 219 217 231\n",
            "  171   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  45 222 214 218 216 210 215 217 202 224\n",
            "  172   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  24 254 214 210 211 214 215 212 203 221\n",
            "  167   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 254 216 215 217 217 216 216 206 225\n",
            "  150   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 247 216 214 217 216 214 212 203 226\n",
            "  136   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 245 216 214 216 217 215 211 204 225\n",
            "  125   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 247 216 214 217 220 217 213 203 222\n",
            "  147   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 248 216 215 218 222 216 214 207 218\n",
            "  179   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 249 216 217 219 222 217 214 210 215\n",
            "  211   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  38 255 214 218 219 224 218 215 211 211\n",
            "  231   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  79 227 209 219 219 227 219 215 213 206\n",
            "  254  58   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 146 226 211 220 219 228 218 215 216 205\n",
            "  219 163   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 202 221 214 221 219 231 218 215 218 213\n",
            "  212 220   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 234 217 216 220 219 234 217 215 218 216\n",
            "  223 247   7   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  17 254 212 219 219 220 233 214 216 219 222\n",
            "  153 238  58   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  66 255 208 220 219 222 241 220 218 218 218\n",
            "  192 242  99   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 142 235 203 218 216 231 242 225 233 219 214\n",
            "  216 238 144   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 177 248 227 229 211 255  76   0 247 243 230\n",
            "  230 249 187   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 101 241 228 228 220 255  64   0 243 237 230\n",
            "  227 241 142   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 255 242 222 218 255  62   0 223 238 225\n",
            "  238 255  31   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  45 255 242 235 255  84   0 246 255 242\n",
            "  255  70   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  61 102 168  25   0 139 161  74\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "Etiqueta: 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fke1i4YQgi8O"
      },
      "source": [
        "Neural Networks learn the best when the data is scaled / normalized to fall in a constant range. One practitioners often use is the range [0,1]. How might you do this to the training and test images used here?\n",
        "\n",
        "*A hint: these images are saved in the standard [RGB](https://www.rapidtables.com/web/color/RGB_Color.html) format*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Uuof9E9Mgi8P"
      },
      "outputs": [],
      "source": [
        "# Normalizar para mejorar el entrenamiento del modelo. Dado que las imÃ¡genes en fashion_mnist tienen valores de pÃ­xeles de 0 a 255, lo\n",
        "# recomendable es escalarlas al rango [0,1] dividiÃ©ndolas por 255.\n",
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lunpa2vNgi8P"
      },
      "source": [
        "Using these improved images lets compile our model using an adaptive optimizer to learn faster and a categorical loss function to differentiate between the the various classes we are trying to classify. Since this is a very simple dataset we will only train for 5 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px4UNbv3gi8Q",
        "outputId": "6e6ea475-ebd2-44f6-fff6-1a13d5bc77c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7960 - loss: 0.5809\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8635 - loss: 0.3730\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8814 - loss: 0.3260\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8934 - loss: 0.2952\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8933 - loss: 0.2845\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8798 - loss: 0.3349\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33859655261039734, 0.8787000179290771]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# compile the model\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fit the model to the training data\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "# test the model on the test data\n",
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JJMsvSB-1UY"
      },
      "source": [
        "Once it's done training -- you should see an accuracy value at the end of the final epoch. It might look something like 0.8648. This tells you that your neural network is about 86% accurate in classifying the training data. I.E., it figured out a pattern match between the image and the labels that worked 86% of the time. But how would it work with unseen data? That's why we have the test images. We can call ```model.evaluate```, and pass in the two sets, and it will report back the loss for each. This should reach about .8747 or thereabouts, showing about 87% accuracy. Not Bad!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rquQqIx4AaGR"
      },
      "source": [
        "But what did it actually learn? If we inference on the model using ```model.predict``` we get out the following list of values. **What does it represent?**\n",
        "\n",
        "*A hint: trying running ```print(test_labels[0])```*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JosyWyYWmHRj",
        "outputId": "04d411ff-6fea-4d9b-fb6a-50c68aff1c49"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyEIki0z_hAD",
        "outputId": "de99c9a3-09a2-4b8a-805e-e36de2817cd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "[2.80221908e-08 1.42001975e-08 3.89301080e-09 1.49849953e-07\n",
            " 1.82927717e-08 2.19534020e-04 2.61936908e-08 1.88999232e-02\n",
            " 9.44435854e-08 9.80880141e-01]\n"
          ]
        }
      ],
      "source": [
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "\n",
        "# El resultado es la salida de la Ãºltima capa de la red neuronal con activaciÃ³n softmax. Es un vector de probabilidades, donde cada\n",
        "# elemento indica la probabilidad de que la imagen pertenezca a una de las 10 clases de Fashion MNIST.\n",
        "# ðŸ“Œ InterpretaciÃ³n del resultado:\n",
        "# * La salida tiene 10 valores, uno por cada categorÃ­a de ropa (zapatos, camisetas, pantalones, etc.).\n",
        "# * Cada nÃºmero es la probabilidad asignada por el modelo a cada clase.\n",
        "# * La posiciÃ³n con el mayor valor representa la predicciÃ³n mÃ¡s probable del modelo.\n",
        "# En tu resultado:\n",
        "# * La mayor probabilidad es 9.80880141e-01 (â‰ˆ 98%), que estÃ¡ en la posiciÃ³n 9.\n",
        "# * Esto significa que el modelo cree que la imagen pertenece a la clase 9 con una alta confianza.\n",
        "# * Si test_labels[0] es tambiÃ©n 9, entonces el modelo hizo una predicciÃ³n correcta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgQSIfDSOWv6"
      },
      "source": [
        "Let's now look at the layers in your model. What happens if you double the number of neurons in the dense layer. What different results do you get for loss, training time etc? Why do you think that's the case?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSZSwV5UObQP",
        "outputId": "53fb8263-9761-4e4b-aaa5-60e1fa3531ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.7945 - loss: 0.5807\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.8652 - loss: 0.3639\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8810 - loss: 0.3263\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - accuracy: 0.8876 - loss: 0.2977\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.8978 - loss: 0.2742\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8811 - loss: 0.3304\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3301563858985901, 0.882099986076355]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "NUMBER_OF_NEURONS = 1024\n",
        "\n",
        "# define the new model\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "                                    tf.keras.layers.Dense(NUMBER_OF_NEURONS, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "# compile fit and evaluate the model again\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0lF5MuvSuZF"
      },
      "source": [
        "Consider the effects of additional layers in the network instead of simply more neurons to the same layer. First update the model to add an additional dense layer into the model between the two existing Dense layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rQk2TUadgi8S"
      },
      "outputs": [],
      "source": [
        "# AÃ±adir otra capa ReLU con menos neuronas\n",
        "# * Reduce progresivamente el nÃºmero de neuronas.\n",
        "# * Mantiene la no linealidad y permite la extracciÃ³n de caracterÃ­sticas.\n",
        "YOUR_NEW_LAYER = tf.keras.layers.Dense(256, activation=tf.nn.relu)\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    YOUR_NEW_LAYER,\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS7JafgVgi8T"
      },
      "source": [
        "Lets then compile, fit, and evaluate our model. What happens to the error? How does this compare to the original model and the model with double the number of neurons?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "b1YPa6UhS8Es",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f259ff89-acca-4237-cf81-04549d07a91c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7934 - loss: 0.5836\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.3660\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8799 - loss: 0.3236\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8891 - loss: 0.2952\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8977 - loss: 0.2734\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8791 - loss: 0.3375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.34281840920448303, 0.8765000104904175]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# compile fit and evaluate the model again\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS3vVkOgCDGZ"
      },
      "source": [
        "Before you trained, you normalized the data. What would be the impact of removing that? To see it for yourself fill in the following lines of code to get a non-normalized set of data and then re-fit and evaluate the model using this data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JDqNAqrpCNg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d7f8374-f05f-4b8b-f6fc-fd27eda911fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6123 - loss: 6.4807\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7022 - loss: 0.7863\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7269 - loss: 0.6865\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7417 - loss: 0.6500\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7544 - loss: 0.6209\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7496 - loss: 0.6652\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# get new non-normalized mnist data\n",
        "training_images_non = training_images * 255.0\n",
        "test_images_non = test_images * 255.0\n",
        "\n",
        "# re-compile, re-fit and re-evaluate\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    YOUR_NEW_LAYER,\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(training_images_non, training_labels, epochs=5)\n",
        "model.evaluate(test_images_non, test_labels)\n",
        "classifications = model.predict(test_images_non)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7W2PT66ZBHQ"
      },
      "source": [
        "Sometimes if you set the training for too many epochs you may find that training stops improving and you wish you could quit early. Good news, you can! TensorFlow has a function called ```Callbacks``` which can check the results from each epoch. Modify this callback function to make sure it exits training early but not before reaching at least the second epoch!\n",
        "\n",
        "*A hint: logs.get(METRIC_NAME) will return the value of METRIC_NAME at the current step*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pkaEHHgqZbYv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f24c1895-bfab-4483-ab5a-21c866727398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7878 - loss: 0.6109\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8620 - loss: 0.3749\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8746 - loss: 0.3355\n",
            "Epoch 4/5\n",
            "\u001b[1m1867/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8849 - loss: 0.3075\n",
            "âœ‹ Entrenamiento detenido: PÃ©rdida menor a 0.3 despuÃ©s de la segunda Ã©poca.\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8849 - loss: 0.3075\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f8390582450>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# define and instantiate your custom Callback\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    # Asegurar que al menos se ejecuten 2 Ã©pocas antes de detenerse\n",
        "    #if epoch >= 1 and logs.get('accuracy') >= 0.90:\n",
        "    #  print(\"\\nâœ‹ Â¡PrecisiÃ³n del 95%! Deteniendo el entrenamiento despuÃ©s de la segunda Ã©poca...\")\n",
        "    if epoch >= 1 and logs.get('loss') <= 0.32: # Detener si la pÃ©rdida es menor o igual a 0.3\n",
        "      print(\"\\nâœ‹ Entrenamiento detenido: PÃ©rdida menor a 0.3 despuÃ©s de la segunda Ã©poca.\")\n",
        "      self.model.stop_training = True\n",
        "callbacks = myCallback()\n",
        "\n",
        "# re-compile, re-fit and re-evaluate\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "                            tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                            YOUR_NEW_LAYER,\n",
        "                            tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "      loss = 'sparse_categorical_crossentropy',\n",
        "      metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "2-2-12-Exercise.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}